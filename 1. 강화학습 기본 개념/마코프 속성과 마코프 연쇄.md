# 강화학습이란?

강화학습(RL, Reinforcement Learning)이란 적절히 설계된 **보상 체계**를 활용해 에이전트가 긍정적인 행동을 할 수 있도록 에이전트 행동을 제어하는 정책을 찾아내는 최적화 기법

머신러닝은 크게 지도학습(Supervised Learning), 비지도학습(Unsupervised Learning), 강화학습으로 구성된다. 지도학습은 정답을 알고 있는, 즉 y값이 있는 데이터로 학습하며, 비지도학습은 정답이 없이 주어진 데이터로만 학습한다. 강화학습은 정답이 주어진 것이 아니며 "보상"을 통해 학습한다.

강화학습을 통해 스스로 학습하는 컴퓨터를 "에이전트"라고 한다. 에이전트는 환경에 대해 사전지식이 없는 상태에서 학습을 한다. 그리고 그 환경으로부터 보상을 받으며 이 보상을 통해 에이전트는 어떤 행동이 좋은 행동인지 간접적으로 알게 된다.

에이전트는 자신의 행동과 그 결과인 보상을 통해 학습하며 어떤 행동을 해야 보상을 많이 얻게 될지를 알게 된다. 강화학습의 목적은 에이전트가 환경을 탐색하면서 얻는 보상을 최대화하는 "최적의 정책(행동양식)"을 학습하는 것이다.

보상을 꼭 양수로 설정할 필요는 없다. 안 좋은 행동을 했을 때는 음수의 보상, 벌점을 줄 수 있다. 적절한 상벌을 통해 에이전트를 잘 학습시키는 게 중요한 문제이다.

정리하자면, **에이전트(Agent)** 는 **정책(Policy)** 에 따라 어떤 **환경 (Environment)** 에서 특정 **행동(Action)** 을 한다. 그러한 행동에 따라 환경의 **상태(State)** 가 바뀌고 상태가 긍정적으로 바뀌 었는지 부정적으로 바뀌었는지에 따라 **보상(Reward)** 을 받는다.

* **강화학습 구성요소**
![강화학습 구성요소](https://github.com/LimSoYeong/Reinforcement-Learning-Study/assets/89073323/f5f981f4-e0e6-4c74-8dad-cb7366a48033)

행동, 상태의 종류가 적은 경우에는 계산을 통해 최적의 정책을 찾을 수 있으나 상태의 종류가 많아질수록 최적의 정책을 찾는 계산 급속하게 증가한다. 이럴 때는 인공신경망 활용한다.
